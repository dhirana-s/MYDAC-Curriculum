{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\desktop\\coding\\mydac-curriculum\\.venv\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\desktop\\coding\\mydac-curriculum\\.venv\\lib\\site-packages (from imbalanced-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\desktop\\coding\\mydac-curriculum\\.venv\\lib\\site-packages (from imbalanced-learn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\desktop\\coding\\mydac-curriculum\\.venv\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\desktop\\coding\\mydac-curriculum\\.venv\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\desktop\\coding\\mydac-curriculum\\.venv\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: xgboost in c:\\desktop\\coding\\mydac-curriculum\\.venv\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in c:\\desktop\\coding\\mydac-curriculum\\.venv\\lib\\site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\desktop\\coding\\mydac-curriculum\\.venv\\lib\\site-packages (from xgboost) (1.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Goal: predict if a company goes bankrupt or not\n",
    "%pip install imbalanced-learn\n",
    "%pip install xgboost\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import imbalanced-learn as imblearn\n",
    "from scipy.stats import kurtosis, skew\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Bankrupt?\n",
      "0    5286\n",
      "1     169\n",
      "Name: count, dtype: int64\n",
      "After SMOTE: Bankrupt?\n",
      "0    5286\n",
      "1    5286\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Accuracy: 0.9531\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1272   41]\n",
      " [  23   28]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1313\n",
      "           1       0.41      0.55      0.47        51\n",
      "\n",
      "    accuracy                           0.95      1364\n",
      "   macro avg       0.69      0.76      0.72      1364\n",
      "weighted avg       0.96      0.95      0.96      1364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = df['Bankrupt?']\n",
    "x = df.drop('Bankrupt?', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42) #initialise SMOTE\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)\n",
    "print(\"Before SMOTE:\", y_train.value_counts())\n",
    "print(\"After SMOTE:\", pd.Series(y_train_smote).value_counts())\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', smote),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42) # Initialize Random Forest\n",
    "model.fit(x_train_smote, y_train_smote) # fit model to trained data\n",
    "\n",
    "y_pred = model.predict(x_test) # make predictions on the test set\n",
    "\n",
    "# Accuracy of model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'\\nAccuracy: {accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a class_weight to the model so that we prioritise minority classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Bankrupt?\n",
      "0    5286\n",
      "1     169\n",
      "Name: count, dtype: int64\n",
      "After SMOTE: Bankrupt?\n",
      "0    5286\n",
      "1    5286\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Accuracy: 0.9531\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1272   41]\n",
      " [  23   28]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1313\n",
      "           1       0.41      0.55      0.47        51\n",
      "\n",
      "    accuracy                           0.95      1364\n",
      "   macro avg       0.69      0.76      0.72      1364\n",
      "weighted avg       0.96      0.95      0.96      1364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = df['Bankrupt?']\n",
    "x = df.drop('Bankrupt?', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42) #initialise SMOTE\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)\n",
    "print(\"Before SMOTE:\", y_train.value_counts())\n",
    "print(\"After SMOTE:\", pd.Series(y_train_smote).value_counts())\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    class_weight={0: 10, 1: 10}\n",
    ") # Initialize Random Forest\n",
    "model.fit(x_train_smote, y_train_smote) # fit model to trained data\n",
    "\n",
    "y_pred = model.predict(x_test) # make predictions on the test set\n",
    "\n",
    "# Accuracy of model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'\\nAccuracy: {accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall has icnreased for class 1 from 55% to 73% - which is great.\n",
    "\n",
    "But ideally, we can increase the precision too since its quite low at only 37% of firms identified to be bankrupt are actually bankrupt. Ie. a lot of false positives. \n",
    "\n",
    "To find an optimal balance for class weights etc. lets do RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Desktop\\coding\\MYDAC-Curriculum\\.venv\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': np.int64(100), 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 20, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(100, 1001, 100),  # Number of trees in the forest (from 100 to 1000)\n",
    "    'max_depth': [None, 10, 20, 30, 40],  # Maximum depth of trees\n",
    "    'min_samples_split': [2, 5, 10, 20],  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4, 10],  # Minimum samples required at leaf node\n",
    "    'class_weight': ['balanced', {0: 10, 1: 1}, {0: 8, 1: 2}]  # Class weights\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # Number of random combinations to test\n",
    "    cv=3,  # Number of cross-validation splits\n",
    "    n_jobs=-1,  # Use all available CPU cores\n",
    "    scoring='recall',  # Optimize for recall\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the randomized search to your training data\n",
    "random_search.fit(x_train_smote, y_train_smote)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(f'Best parameters: {random_search.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Desktop\\coding\\MYDAC-Curriculum\\.venv\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'rf__n_estimators': 300, 'rf__min_samples_split': 5, 'rf__min_samples_leaf': 2, 'rf__max_depth': None, 'rf__class_weight': {0: 10, 1: 1}}\n",
      "Before SMOTE: Bankrupt?\n",
      "0    5286\n",
      "1     169\n",
      "Name: count, dtype: int64\n",
      "After SMOTE: Bankrupt?\n",
      "0    5286\n",
      "1    5286\n",
      "Name: count, dtype: int64\n",
      "Cross-validation scores: [0.55002089 0.57946951 0.60327903 0.59732665 0.59137427 0.60902256\n",
      " 0.5914787  0.61518379 0.57967836 0.54991646 0.61507937 0.55012531\n",
      " 0.62708855 0.59743108 0.54981203 0.58542189 0.54396408 0.5914787\n",
      " 0.56182122 0.60338346 0.59732665 0.46094403 0.58552632 0.58542189\n",
      " 0.58552632 0.61518379 0.58563074 0.64452799 0.4789056  0.61518379\n",
      " 0.54417293 0.60923141 0.60912698 0.48475355 0.58552632 0.60327903\n",
      " 0.61518379 0.60338346 0.55002089 0.57372598 0.54396408 0.61518379\n",
      " 0.5380117  0.52621136 0.55576441 0.58552632 0.57967836 0.57967836\n",
      " 0.54991646 0.59743108]\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1261   52]\n",
      " [  14   37]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      1313\n",
      "           1       0.42      0.73      0.53        51\n",
      "\n",
      "    accuracy                           0.95      1364\n",
      "   macro avg       0.70      0.84      0.75      1364\n",
      "weighted avg       0.97      0.95      0.96      1364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "y = df['Bankrupt?']\n",
    "x = df.drop('Bankrupt?', axis=1)\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [100, 200, 300, 500],  # Number of trees\n",
    "    'rf__min_samples_split': [2, 5, 10, 15],   # Minimum samples required to split a node\n",
    "    'rf__min_samples_leaf': [1, 2, 4, 6],     # Minimum samples required at leaf node\n",
    "    'rf__max_depth': [None, 10, 20, 30, 40],   # Maximum depth of trees\n",
    "    'rf__class_weight': ['balanced', {0: 10, 1: 1}, {0: 8, 1: 2}, {0: 5, 1: 3}]  # Class weights\n",
    "}\n",
    "\n",
    "# Create a pipeline that first applies SMOTE, then trains Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('smote', smote),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Set up RandomizedSearchCV with recall as the scoring metric\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Number of random combinations to test\n",
    "    cv=3,  # Number of cross-validation splits\n",
    "    n_jobs=-1,  # Use all available CPU cores\n",
    "    scoring='recall',  # Optimize for recall\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model using RandomizedSearchCV\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters found by RandomizedSearchCV\n",
    "print(f'Best parameters: {random_search.best_params_}')\n",
    "\n",
    "# Get the best model found by RandomizedSearchCV\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "print(\"Before SMOTE:\", y_train.value_counts())\n",
    "print(\"After SMOTE:\", pd.Series(y_train_smote).value_counts())\n",
    "\n",
    "cv_scores = random_search.cv_results_['mean_test_score']\n",
    "print(f'Cross-validation scores: {cv_scores}')\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying again while account for computational power. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
