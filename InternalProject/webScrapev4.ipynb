{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important aspects of EV Charging to focus on:\n",
    "- charging efficiency\n",
    "- station availability\n",
    "- station reliability\n",
    "- cost of charging\n",
    "- charger comptabiliity\n",
    "- range anxiety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Reddit API\n",
    "import praw\n",
    "\n",
    "# Natural Language Processing (NLP)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Topic Modeling\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "# Visualization\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "# Transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "# Miscellaneous\n",
    "from pprint import pprint\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize Reddit API\n",
    "# reddit = praw.Reddit(\n",
    "#     client_id=open('cred/client_id.txt').read().strip(),\n",
    "#     client_secret=open('cred/client_secret.txt').read().strip(),\n",
    "#     user_agent=open('cred/user_agent.txt').read().strip(),\n",
    "# )\n",
    "\n",
    "# # Define Reddit post URL\n",
    "# reddit_post_url = \"https://www.reddit.com/r/electricvehicles/comments/1e7x13p/it_is_not_the_evs_that_are_lacking_in_the_us_its/\"\n",
    "# submission = reddit.submission(url=reddit_post_url)\n",
    "\n",
    "# # Create a list to hold post and comment data\n",
    "# post_data = {\n",
    "#     'post_id': submission.id,\n",
    "#     'post_title': submission.title,\n",
    "#     'post_text': submission.selftext,\n",
    "#     'post_score': submission.score,\n",
    "#     'post_author': submission.author.name if submission.author else \"Deleted\",\n",
    "# }\n",
    "\n",
    "# comments_data = []\n",
    "\n",
    "# # Fetch comments and store them\n",
    "# submission.comments.replace_more(limit=None)\n",
    "\n",
    "# # Scrape comments\n",
    "# for comment in submission.comments.list():\n",
    "#     comments_data.append({\n",
    "#         'comment_id': comment.id,\n",
    "#         'author': comment.author.name if comment.author else \"Deleted\",\n",
    "#         'score': comment.score,\n",
    "#         'comment_text': comment.body\n",
    "#     })\n",
    "\n",
    "# # Create DataFrames\n",
    "# post_df = pd.DataFrame([post_data])  # The post data will be a single row\n",
    "# comments_df = pd.DataFrame(comments_data)\n",
    "\n",
    "# # Display the data (Post Content and Comments)\n",
    "# print(\"Post Data:\")\n",
    "# print(post_df.head())  # Only showing post info (first row)\n",
    "# print(\"\\nComments Data:\")\n",
    "# print(comments_df.head())  # Display the first few comments\n",
    "\n",
    "# # Optionally: Save to CSV or JSON if needed\n",
    "# post_df.to_csv(\"post_data.csv\", index=False)\n",
    "# comments_df.to_csv(\"comments_data.csv\", index=False)\n",
    "\n",
    "# # Sleep for 60 seconds before scraping again\n",
    "# time.sleep(60)  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aspects = [\n",
    "#     \"Charging stations\",\n",
    "#     \"Charging network\",\n",
    "#     \"Range anxiety\",\n",
    "#     \"Charging speed\",\n",
    "#     \"Charger type\",\n",
    "#     \"Availability of chargers\",\n",
    "#     \"Cost of charging\",\n",
    "#     \"Maintenance issues\",\n",
    "#     \"Tesla charging network\",\n",
    "#     \"EV range\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# # preprocess comments: Convert to lowercase and remove special characters\n",
    "# def preprocess_text(text):\n",
    "#     text = text.lower()  # Convert to lowercase\n",
    "#     text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with one\n",
    "#     text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation and special characters\n",
    "#     return text\n",
    "\n",
    "# # categorise comments depending on aspects identified above\n",
    "# def categorize_comment(comment_text, aspects):\n",
    "#     categories = []\n",
    "#     for aspect in aspects:\n",
    "#         if aspect.lower() in comment_text:\n",
    "#             categories.append(aspect)\n",
    "#     return categories\n",
    "\n",
    "\n",
    "# # -------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# categorized_comments = []\n",
    "\n",
    "# for comment in comments_df.itertuples():\n",
    "#     comment_text = preprocess_text(comment.comment_text)  # Preprocess the comment text\n",
    "#     categories = categorize_comment(comment_text, aspects)\n",
    "    \n",
    "#     # Store the result along with the original comment data\n",
    "#     categorized_comments.append({\n",
    "#         'comment_id': comment.comment_id,\n",
    "#         'author': comment.author,\n",
    "#         'score': comment.score,\n",
    "#         'comment_text': comment.comment_text,\n",
    "#         'categories': categories\n",
    "#     })\n",
    "\n",
    "# # Create a DataFrame for categorized comments\n",
    "# categorized_comments_df = pd.DataFrame(categorized_comments)\n",
    "\n",
    "# # Display categorized comments\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# print(categorized_comments_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_counts = categorized_comments_df['categories'].explode().value_counts()\n",
    "# print(category_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECOND TRY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import KeyedVectors\n",
    "\n",
    "# # Load Google's pre-trained Word2Vec model (download it if needed)\n",
    "# # This is a large model, so you may want to store it locally and load it\n",
    "# # model = KeyedVectors.load_word2vec_format('path/to/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# # For this example, we’ll use a smaller, faster model from Gensim\n",
    "# from gensim.models import Word2Vec\n",
    "\n",
    "# # Train a small model on your dataset if you don't want to use a pre-trained model\n",
    "# # Example using your comments data\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# # Tokenize all comments (lowercase)\n",
    "# tokenized_comments = [word_tokenize(comment.lower()) for comment in comments_df['comment_text']]\n",
    "\n",
    "# # Train Word2Vec model on the tokenized data\n",
    "# word2vec_model = Word2Vec(tokenized_comments, vector_size=100, window=5, min_count=1, sg=0)\n",
    "# word2vec_model.save(\"word2vec.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# # Assuming you already have the comments_df\n",
    "# comments_data = comments_df['comment_text']\n",
    "\n",
    "# # Load pre-trained Word2Vec model (or your own)\n",
    "# word2vec_model = Word2Vec.load(\"word2vec.model\")\n",
    "\n",
    "# # Define broad theme words based on your categories\n",
    "# theme_words = {\n",
    "#     'satisfaction': ['good', 'excellent', 'love', 'great', 'enjoy'],\n",
    "#     'frustration': ['bad', 'slow', 'delay', 'frustrating', 'worse'],\n",
    "#     'charging_stations': ['station', 'stations', 'location', 'public station', 'charging point', 'infrastructure', 'charger', 'kiosk', 'EV station', 'public chargers', 'station network', 'station availability'],\n",
    "#     'charging_network': ['network', 'connected', 'networked', 'charging grid', 'network coverage', 'roaming', 'charging locations', 'map', 'network reliability', 'network expansion', 'partner network'],\n",
    "#     'range_anxiety': ['range', 'range anxiety', 'range fear', 'battery life', 'battery capacity', 'distance', 'travel range', 'anxiety', 'worry', 'trip range', 'unable to charge', 'running out of charge', 'mileage'],\n",
    "#     'charging_speed': ['fast', 'slow', 'speed', 'charging rate', 'fast-charging', 'quick', 'fast charging', 'charging speed', 'time to charge', 'slow charging', 'quick charge', 'fast charger', 'fast charging stations'],\n",
    "#     'charger_type': ['charger', 'type', 'level 1', 'level 2', 'DC fast charging', 'supercharger', 'home charger', 'wall box', 'charging adapter', 'charging port', 'connector', 'plug type', 'Type 1', 'Type 2', 'CCS', 'CHAdeMO'],\n",
    "#     'availability_of_chargers': ['available', 'not available', 'missing', 'rare', 'insufficient', 'availability', 'location', 'access', 'scarce', 'scarce charging', 'find chargers', 'nearby', 'accessible', 'not available', 'out of service', 'open station', 'charger access', 'charger shortage'],\n",
    "#     'cost_of_charging': ['cost', 'price', 'expensive', 'affordable', 'cheap', 'price per kWh', 'electricity cost', 'costly', 'charging fees', 'rates', 'price of charging', 'cost to charge', 'free charging', 'charging cost', 'pricing model', 'pricing scheme', 'cost per session'],\n",
    "#     'maintenance_issues': ['maintenance', 'repair', 'broken', 'malfunction', 'service', 'failure', 'out of service', 'maintenance required', 'charger broken', 'charger error', 'service required', 'maintenance costs', 'down time', 'maintenance issues'],\n",
    "#     'tesla_charging_network': ['Tesla', 'supercharger', 'Tesla chargers', 'Tesla network', 'Tesla charging', 'supercharger station', 'Tesla charging stations', 'Tesla infrastructure', 'Tesla owners', 'Tesla charging speed'],\n",
    "#     'ev_range': ['EV', 'range', 'battery', 'miles', 'distance', 'range per charge', 'battery life', 'vehicle range', 'driving range', 'range capacity', 'charge range', 'range efficiency']\n",
    "# }\n",
    "\n",
    "\n",
    "# # Helper function to find the most similar theme based on Word2Vec embeddings\n",
    "# def get_similarity_score(comment, theme_words, model):\n",
    "#     # Tokenize the comment\n",
    "#     tokens = word_tokenize(comment.lower())\n",
    "    \n",
    "#     # Calculate average vector for the comment\n",
    "#     vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    \n",
    "#     if not vectors:\n",
    "#         return None\n",
    "    \n",
    "#     # Calculate the average vector for the comment\n",
    "#     avg_comment_vector = np.mean(vectors, axis=0)\n",
    "    \n",
    "#     # Create a dictionary to store the similarity score for each theme\n",
    "#     similarity_scores = {}\n",
    "    \n",
    "#     for theme, words in theme_words.items():\n",
    "#         theme_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "#         avg_theme_vector = np.mean(theme_vectors, axis=0)\n",
    "        \n",
    "#         # Compute cosine similarity between the comment vector and theme vector\n",
    "#         similarity_scores[theme] = np.dot(avg_comment_vector, avg_theme_vector) / (np.linalg.norm(avg_comment_vector) * np.linalg.norm(avg_theme_vector))\n",
    "    \n",
    "#     return similarity_scores\n",
    "\n",
    "# # Now process the comments and categorize based on the most relevant theme\n",
    "# categorized_comments = []\n",
    "\n",
    "# for comment in comments_data:\n",
    "#     similarity_scores = get_similarity_score(comment, theme_words, word2vec_model)\n",
    "    \n",
    "#     if similarity_scores:\n",
    "#         # Find the most relevant theme by selecting the highest similarity score\n",
    "#         most_relevant_theme = max(similarity_scores, key=similarity_scores.get)\n",
    "#         categorized_comments.append(most_relevant_theme)\n",
    "#     else:\n",
    "#         categorized_comments.append(\"uncategorized\")\n",
    "\n",
    "# # Add categorized themes to your DataFrame\n",
    "# comments_df['theme'] = categorized_comments\n",
    "\n",
    "# # Display the categorized comments\n",
    "\n",
    "# print(comments_df.head())\n",
    "\n",
    "# # Optionally: Save to CSV or JSON if needed\n",
    "# comments_df.to_csv(\"categorized_comments.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Data:\n",
      "   post_id                                         post_title  \\\n",
      "0  1e7x13p  It is not the EVs, that are lacking in the US,...   \n",
      "\n",
      "                                           post_text  post_score post_author  \n",
      "0  So, I own a ICE vehicle, but often will rent E...         373  Ok-Pea3414  \n",
      "\n",
      "Comments Data:\n",
      "  comment_id              author  score  \\\n",
      "0    le387km             Deleted    116   \n",
      "1    le39p6l          Dirks_Knee     62   \n",
      "2    le3j257  iwantthisnowdammit     30   \n",
      "3    le4yq2n          iSeerStone      9   \n",
      "4    le3icon           StLandrew      8   \n",
      "\n",
      "                                        comment_text  \\\n",
      "0  We need a lot more L2 AC to reduce the need of...   \n",
      "1  You're kinda the inverse example which highlig...   \n",
      "2  We’re in the “before USB outlets on airplanes”...   \n",
      "3  Chargers should be:\\n1. Maintained like gas pu...   \n",
      "4  I have to record this for posterity. \"I own a ...   \n",
      "\n",
      "                                              themes  \n",
      "0                                     [charger_type]  \n",
      "1  [charging_stations, maintenance_issues, ev_range]  \n",
      "2                                                 []  \n",
      "3                                                 []  \n",
      "4  [charging_stations, charging_network, tesla_ch...  \n"
     ]
    }
   ],
   "source": [
    "# Initialize Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=open('cred/client_id.txt').read().strip(),\n",
    "    client_secret=open('cred/client_secret.txt').read().strip(),\n",
    "    user_agent=open('cred/user_agent.txt').read().strip(),\n",
    ")\n",
    "\n",
    "# Define Reddit post URL\n",
    "reddit_post_url = \"https://www.reddit.com/r/electricvehicles/comments/1e7x13p/it_is_not_the_evs_that_are_lacking_in_the_us_its/\"\n",
    "submission = reddit.submission(url=reddit_post_url)\n",
    "\n",
    "# Define the theme words for each aspect\n",
    "theme_words = {\n",
    "    'charging_stations': ['station', 'stations', 'location', 'public station', 'charging point', 'infrastructure', 'charger', 'kiosk', 'EV station', 'public chargers', 'station network', 'station availability'],\n",
    "    'charging_network': ['network', 'connected', 'networked', 'charging grid', 'network coverage', 'roaming', 'charging locations', 'map', 'network reliability', 'network expansion', 'partner network'],\n",
    "    'range_anxiety': ['range', 'range anxiety', 'range fear', 'battery life', 'battery capacity', 'distance', 'travel range', 'anxiety', 'worry', 'trip range', 'unable to charge', 'running out of charge', 'mileage'],\n",
    "    'charging_speed': ['fast', 'slow', 'speed', 'charging rate', 'fast-charging', 'quick', 'fast charging', 'charging speed', 'time to charge', 'slow charging', 'quick charge', 'fast charger', 'fast charging stations'],\n",
    "    'availability_of_chargers': ['available', 'availability', 'location', 'access', 'scarce', 'scarce charging', 'find chargers', 'nearby', 'accessible', 'not available', 'out of service', 'open station', 'charger access', 'charger shortage'],\n",
    "    'cost_of_charging': ['cost', 'price', 'expensive', 'affordable', 'cheap', 'price per kWh', 'electricity cost', 'charging fees', 'rates', 'price of charging', 'cost to charge', 'free charging', 'charging cost', 'pricing model', 'pricing scheme', 'cost per session'],\n",
    "    'maintenance_issues': ['maintenance', 'repair', 'broken', 'malfunction', 'service', 'failure', 'out of service', 'maintenance required', 'charger broken', 'charger error', 'service required', 'maintenance costs', 'down time', 'maintenance issues'],\n",
    "    'tesla_charging_network': ['Tesla', 'supercharger', 'Tesla chargers', 'Tesla network', 'Tesla charging', 'supercharger station', 'Tesla charging stations', 'Tesla infrastructure', 'Tesla owners', 'Tesla charging speed'],\n",
    "    'ev_range': ['EV', 'range', 'battery', 'miles', 'distance', 'range per charge', 'battery life', 'vehicle range', 'driving range', 'range capacity', 'charge range', 'range efficiency'],\n",
    "    \n",
    "\n",
    "    'vehicle model': ['tesla model 3', 'hyundai kona', 'nissan leaf', 'chevy bolt', 'bmw i3'],\n",
    "    'charging_station_location': ['houston', 'san francisco', 'los angeles', 'chicago', 'new york'],\n",
    "    'charger_type': ['charger', 'type', 'level 1', 'level 2', 'DC fast charging', 'DC fast charger', 'supercharger', 'home charger', 'wall box', 'charging adapter', 'charging port', 'connector', 'plug type', 'Type 1', 'Type 2', 'CCS', 'CHAdeMO', 'L2', 'L1'],\n",
    "}\n",
    "\n",
    "# Create a list to hold post and comment data\n",
    "post_data = {\n",
    "    'post_id': submission.id,\n",
    "    'post_title': submission.title,\n",
    "    'post_text': submission.selftext,\n",
    "    'post_score': submission.score,\n",
    "    'post_author': submission.author.name if submission.author else \"Deleted\",\n",
    "}\n",
    "\n",
    "comments_data = []\n",
    "\n",
    "# Fetch comments and store them\n",
    "submission.comments.replace_more(limit=None)\n",
    "\n",
    "# Function to categorize a comment into multiple themes\n",
    "def categorize_comment(comment_text, theme_synonyms):\n",
    "    categorized_themes = []\n",
    "    for theme, synonyms in theme_synonyms.items():\n",
    "        for synonym in synonyms:\n",
    "            if re.search(r'\\b' + re.escape(synonym) + r'\\b', comment_text, re.IGNORECASE):\n",
    "                categorized_themes.append(theme)\n",
    "                break\n",
    "    return categorized_themes\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "\n",
    "# Scrape comments and categorize them\n",
    "for comment in submission.comments.list():\n",
    "    comment_text = comment.body\n",
    "    matched_themes = categorize_comment(comment_text, theme_words)\n",
    "    \n",
    "    comments_data.append({\n",
    "        'comment_id': comment.id,\n",
    "        'author': comment.author.name if comment.author else \"Deleted\",\n",
    "        'score': comment.score,\n",
    "        'comment_text': comment_text,\n",
    "        'themes': matched_themes  # Store all matched themes\n",
    "    })\n",
    "\n",
    "# Create DataFrames\n",
    "post_df = pd.DataFrame([post_data])  # The post data will be a single row\n",
    "comments_df = pd.DataFrame(comments_data)\n",
    "\n",
    "# Display the data (Post Content and Comments)\n",
    "print(\"Post Data:\")\n",
    "print(post_df.head())  # Only showing post info (first row)\n",
    "print(\"\\nComments Data:\")\n",
    "print(comments_df.head())  # Display the first few comments\n",
    "\n",
    "# Optionally: Save to CSV or JSON if needed\n",
    "post_df.to_csv(\"post_data.csv\", index=False)\n",
    "comments_df.to_csv(\"comments_data.csv\", index=False)\n",
    "\n",
    "# Sleep for 60 seconds before scraping again\n",
    "time.sleep(60)  # Adjust as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=open('cred/client_id.txt').read().strip(),\n",
    "    client_secret=open('cred/client_secret.txt').read().strip(),\n",
    "    user_agent=open('cred/user_agent.txt').read().strip(),\n",
    ")\n",
    "\n",
    "# Define Reddit post URL\n",
    "reddit_post_url = \"https://www.reddit.com/r/electricvehicles/comments/1e7x13p/it_is_not_the_evs_that_are_lacking_in_the_us_its/\"\n",
    "submission = reddit.submission(url=reddit_post_url)\n",
    "\n",
    "# Define the theme words for each aspect (same as your current code)\n",
    "theme_words = {\n",
    "    'charging_stations': ['station', 'stations', 'location', 'public station', 'charging point', 'infrastructure', 'charger', 'kiosk', 'EV station', 'public chargers', 'station network', 'station availability'],\n",
    "    'charging_network': ['network', 'connected', 'networked', 'charging grid', 'network coverage', 'roaming', 'charging locations', 'map', 'network reliability', 'network expansion', 'partner network'],\n",
    "    'range_anxiety': ['range', 'range anxiety', 'range fear', 'battery life', 'battery capacity', 'distance', 'travel range', 'anxiety', 'worry', 'trip range', 'unable to charge', 'running out of charge', 'mileage'],\n",
    "    'charging_speed': ['fast', 'slow', 'speed', 'charging rate', 'fast-charging', 'quick', 'fast charging', 'charging speed', 'time to charge', 'slow charging', 'quick charge', 'fast charger', 'fast charging stations'],\n",
    "    'availability_of_chargers': ['available', 'availability', 'location', 'access', 'scarce', 'scarce charging', 'find chargers', 'nearby', 'accessible', 'not available', 'out of service', 'open station', 'charger access', 'charger shortage'],\n",
    "    'cost_of_charging': ['cost', 'price', 'expensive', 'affordable', 'cheap', 'price per kWh', 'electricity cost', 'charging fees', 'rates', 'price of charging', 'cost to charge', 'free charging', 'charging cost', 'pricing model', 'pricing scheme', 'cost per session'],\n",
    "    'maintenance_issues': ['maintenance', 'repair', 'broken', 'malfunction', 'service', 'failure', 'out of service', 'maintenance required', 'charger broken', 'charger error', 'service required', 'maintenance costs', 'down time', 'maintenance issues'],\n",
    "    'tesla_charging_network': ['Tesla', 'supercharger', 'Tesla chargers', 'Tesla network', 'Tesla charging', 'supercharger station', 'Tesla charging stations', 'Tesla infrastructure', 'Tesla owners', 'Tesla charging speed'],\n",
    "    'ev_range': ['EV', 'range', 'battery', 'miles', 'distance', 'range per charge', 'battery life', 'vehicle range', 'driving range', 'range capacity', 'charge range', 'range efficiency'],\n",
    "    'vehicle model': ['tesla model 3', 'hyundai kona', 'nissan leaf', 'chevy bolt', 'bmw i3'],\n",
    "    'charging_station_location': ['houston', 'san francisco', 'los angeles', 'chicago', 'new york'],\n",
    "    'charger_type': ['charger', 'type', 'level 1', 'level 2', 'DC fast charging', 'DC fast charger', 'supercharger', 'home charger', 'wall box', 'charging adapter', 'charging port', 'connector', 'plug type', 'Type 1', 'Type 2', 'CCS', 'CHAdeMO', 'L2', 'L1'],\n",
    "}\n",
    "\n",
    "# Create a list to hold post and comment data\n",
    "post_data = {\n",
    "    'post_id': submission.id,\n",
    "    'post_title': submission.title,\n",
    "    'post_text': submission.selftext,\n",
    "    'post_score': submission.score,\n",
    "    'post_author': submission.author.name if submission.author else \"Deleted\",\n",
    "}\n",
    "\n",
    "comments_data = []\n",
    "\n",
    "# Fetch comments and store them\n",
    "submission.comments.replace_more(limit=None)\n",
    "\n",
    "# Initialize BERT-based sentiment analysis model\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Function to categorize a comment into multiple themes using BERT-based model\n",
    "def categorize_comment_bert(comment_text, candidate_labels):\n",
    "    # Using zero-shot classification to predict themes\n",
    "    result = classifier(comment_text, candidate_labels)\n",
    "    return result['labels']\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Scrape comments and categorize them\n",
    "for comment in submission.comments.list():\n",
    "    comment_text = comment.body\n",
    "    matched_themes = categorize_comment_bert(comment_text, list(theme_words.keys()))  # Using BERT for classification\n",
    "    \n",
    "    comments_data.append({\n",
    "        'comment_id': comment.id,\n",
    "        'author': comment.author.name if comment.author else \"Deleted\",\n",
    "        'score': comment.score,\n",
    "        'comment_text': comment_text,\n",
    "        'themes': matched_themes  # Store all matched themes\n",
    "    })\n",
    "\n",
    "# Create DataFrames\n",
    "post_df = pd.DataFrame([post_data])  # The post data will be a single row\n",
    "comments_df = pd.DataFrame(comments_data)\n",
    "\n",
    "# Display the data (Post Content and Comments)\n",
    "print(\"Post Data:\")\n",
    "print(post_df.head())  # Only showing post info (first row)\n",
    "print(\"\\nComments Data:\")\n",
    "print(comments_df.head())  # Display the first few comments\n",
    "\n",
    "# Optionally: Save to CSV or JSON if needed\n",
    "post_df.to_csv(\"post_data.csv\", index=False)\n",
    "comments_df.to_csv(\"comments_data.csv\", index=False)\n",
    "\n",
    "# Sleep for 60 seconds before scraping again\n",
    "time.sleep(60)  # Adjust as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts to scrape: ['https://www.reddit.com/r/electricvehicles/comments/1eqk69a/tesla_is_not_a_luxury_vehicle/', 'https://www.reddit.com/r/electricvehicles/comments/152536h/as_a_conservative_i_hated_the_idea_of_owning_an/', 'https://www.reddit.com/r/electricvehicles/comments/13r4skr/bought_a_very_cheap_ev_two_weeks_ago_and_its/', 'https://www.reddit.com/r/electricvehicles/comments/1ekjapv/psa_avoid_the_chevrolet_blazer_ev/', 'https://www.reddit.com/r/electricvehicles/comments/16df0wz/ill_never_understand_naysayers/', 'https://www.reddit.com/r/electricvehicles/comments/12hn48z/five_years_of_model_3_ownership_by_the_numbers/', 'https://www.reddit.com/gallery/z4x6ve', 'https://i.redd.it/tndowc3qt7ad1.png', 'https://www.reddit.com/r/electricvehicles/comments/18zam6a/my_ev_is_now_10_years_old_pros_and_cons_of_owning/', 'https://i.redd.it/ousp1fmu2cg81.jpg']\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "\n",
    "# Initialize Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=open('cred/client_id.txt').read().strip(),\n",
    "    client_secret=open('cred/client_secret.txt').read().strip(),\n",
    "    user_agent=open('cred/user_agent.txt').read().strip(),\n",
    ")\n",
    "\n",
    "# Define a list of keywords related to EV charging\n",
    "keywords = ['charging stations', 'EV charging', 'Tesla charging', 'range anxiety', 'charging cost']\n",
    "\n",
    "# Define a subreddit to search in\n",
    "subreddit = reddit.subreddit('electricvehicles')  # or 'evcharging', 'EV', etc.\n",
    "\n",
    "# Fetch top posts or new posts based on keywords\n",
    "posts_to_scrape = []\n",
    "\n",
    "# Search posts for specific keywords and filter by engagement\n",
    "for submission in subreddit.search(\" OR \".join(keywords), sort='top', time_filter='all', limit=10):\n",
    "    if submission.num_comments > 10 and submission.score > 100:  # Filter based on popularity\n",
    "        posts_to_scrape.append(submission.url)\n",
    "\n",
    "# Print the URLs of posts to scrape\n",
    "print(\"Posts to scrape:\", posts_to_scrape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "# Initialize Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=open('cred/client_id.txt').read().strip(),\n",
    "    client_secret=open('cred/client_secret.txt').read().strip(),\n",
    "    user_agent=open('cred/user_agent.txt').read().strip(),\n",
    ")\n",
    "\n",
    "# Define a list of keywords related to vehicle models and cities\n",
    "keywords = [\n",
    "    \"Tesla Model 3\", \"Hyundai Kona\", \"Nissan Leaf\", \"Chevy Bolt\", \"BMW i3\",\n",
    "    \"Houston EV charging\", \"San Francisco EV stations\", \"Los Angeles charging network\", \n",
    "    \"Chicago Tesla Superchargers\", \"New York public chargers\"\n",
    "]\n",
    "\n",
    "# Define a subreddit to search in\n",
    "subreddit = reddit.subreddit('electricvehicles')  # You can add others like 'evcharging' or 'teslamotors'\n",
    "\n",
    "# Fetch top posts or new posts based on keywords\n",
    "posts_to_scrape = []\n",
    "\n",
    "# Search posts for specific keywords and filter by engagement\n",
    "for submission in subreddit.search(\" OR \".join(keywords), sort='top', time_filter='all', limit=10):\n",
    "    if submission.num_comments > 10 and submission.score > 100:  # Filter based on popularity\n",
    "        posts_to_scrape.append(submission.url)\n",
    "\n",
    "# Print the URLs of posts to scrape, each on a new line\n",
    "print(\"Posts to scrape:\")\n",
    "for post in posts_to_scrape:\n",
    "    print(post)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
