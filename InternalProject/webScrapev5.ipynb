{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, time\n",
    "import requests, json\n",
    "import re, string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Reddit API\n",
    "import praw\n",
    "\n",
    "# Natural Language Processing (NLP)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Topic Modeling\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "# Visualization\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "# Transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "# Miscellaneous\n",
    "from pprint import pprint\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to reddit_posts_and_comments.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=open('cred/client_id.txt').read().strip(),\n",
    "    client_secret=open('cred/client_secret.txt').read().strip(),\n",
    "    user_agent=open('cred/user_agent.txt').read().strip(),\n",
    ")\n",
    "\n",
    "# Hard-coded list of Reddit post URLs to scrape\n",
    "posts_to_scrape = [\n",
    "    \"https://www.reddit.com/r/electriccars/comments/1cr9w0q/32_of_consumers_were_considering_an_ev_but_cited/\",\n",
    "    \"https://www.reddit.com/r/electricvehicles/comments/1e7x13p/it_is_not_the_evs_that_are_lacking_in_the_us_its\",\n",
    "    \"https://www.reddit.com/r/electriccars/comments/1c1gtn9/wait_its_an_ev_details_in_comments/\",\n",
    "    \"https://www.reddit.com/r/science/comments/4xym1e/range_anxiety_is_scaring_people_away_from/\",\n",
    "    \"https://www.reddit.com/r/cars/comments/10wfm08/this_is_ruining_electric_cars_the_charging/\",\n",
    "    \"https://www.reddit.com/r/electricvehicles/comments/11ztuhi/ive_owned_an_electric_car_for_four_months_and_not/\",\n",
    "    \"https://www.reddit.com/r/electricvehicles/comments/1gsqza5/four_dead_in_fire_as_tesla_doors_fail_to_open/\",\n",
    "    \"https://www.reddit.com/r/cars/comments/rshvy0/why_i_sold_my_tesla_model_3_performance_went_back/\"\n",
    "]\n",
    "\n",
    "# List to hold all data\n",
    "data = []\n",
    "\n",
    "# Fetch data for each post\n",
    "for post_url in posts_to_scrape:\n",
    "    submission = reddit.submission(url=post_url)\n",
    "    \n",
    "    # Get post details\n",
    "    post_info = {\n",
    "        'post_id': submission.id,\n",
    "        'post_url': submission.url,\n",
    "        'post_title': submission.title,\n",
    "        'post_text': submission.selftext,\n",
    "        'post_score': submission.score,\n",
    "        'post_author': submission.author.name if submission.author else \"Deleted\",\n",
    "        'comment_id': None,  # Placeholder for comments\n",
    "        'comment_author': None,\n",
    "        'comment_text': None,\n",
    "        'comment_score': None\n",
    "    }\n",
    "    \n",
    "    # Add post info to the data list\n",
    "    data.append(post_info)\n",
    "    \n",
    "    # Scrape comments\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    for comment in submission.comments.list():\n",
    "        comment_info = {\n",
    "            'post_id': submission.id,\n",
    "            'post_url': submission.url,\n",
    "            'post_title': submission.title,\n",
    "            'post_text': submission.selftext,\n",
    "            'post_score': submission.score,\n",
    "            'post_author': submission.author.name if submission.author else \"Deleted\",\n",
    "            'comment_id': comment.id,\n",
    "            'comment_author': comment.author.name if comment.author else \"Deleted\",\n",
    "            'comment_text': comment.body,\n",
    "            'comment_score': comment.score\n",
    "        }\n",
    "        data.append(comment_info)\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = \"reddit_posts_and_comments.csv\"\n",
    "df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "print(f\"Data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   post_id                                           post_url  \\\n",
      "0  1cr9w0q  https://thefutureeconomy.ca/op-eds/vehicle-to-...   \n",
      "1  1cr9w0q  https://thefutureeconomy.ca/op-eds/vehicle-to-...   \n",
      "2  1cr9w0q  https://thefutureeconomy.ca/op-eds/vehicle-to-...   \n",
      "3  1cr9w0q  https://thefutureeconomy.ca/op-eds/vehicle-to-...   \n",
      "4  1cr9w0q  https://thefutureeconomy.ca/op-eds/vehicle-to-...   \n",
      "\n",
      "                                          post_title post_text  post_score  \\\n",
      "0  32% of consumers were considering an EV but ci...       NaN         574   \n",
      "1  32% of consumers were considering an EV but ci...       NaN         574   \n",
      "2  32% of consumers were considering an EV but ci...       NaN         574   \n",
      "3  32% of consumers were considering an EV but ci...       NaN         574   \n",
      "4  32% of consumers were considering an EV but ci...       NaN         574   \n",
      "\n",
      "     post_author comment_id comment_author  \\\n",
      "0  northstrong87        NaN            NaN   \n",
      "1  northstrong87    l3wwg7h    XxFezzgigxX   \n",
      "2  northstrong87    l3wufnj   mickthomas68   \n",
      "3  northstrong87    l3wochb    Betanumerus   \n",
      "4  northstrong87    l3wqcrs    bhilliardga   \n",
      "\n",
      "                                        comment_text  comment_score  \n",
      "0                                                NaN            NaN  \n",
      "1  No worries. As soon as batteries become more e...           15.0  \n",
      "2  I was skeptical at first, but as I already had...           34.0  \n",
      "3  People who can charge at home have no excuse r...           30.0  \n",
      "4  Iâ€™ve had my ford lightning for 2 months and fo...            7.0  \n",
      "Cleaned data saved to reddit_posts_and_comments_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# # Load the CSV file\n",
    "# df = pd.read_csv(\"reddit_posts_and_comments.csv\")\n",
    "\n",
    "# # 1. Drop rows with missing content (e.g., deleted posts/comments)\n",
    "# df = df.dropna(subset=['post_title', 'post_text', 'comment_text'], how='all').reset_index(drop=True)\n",
    "\n",
    "# # 2. Remove duplicates\n",
    "# df = df.drop_duplicates()\n",
    "\n",
    "# # 3. Handle special characters in text fields (e.g., emojis or non-ASCII characters)\n",
    "# def clean_text(text):\n",
    "#     if pd.isna(text):  # Check for NaN\n",
    "#         return text\n",
    "#     text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove non-ASCII characters\n",
    "#     text = re.sub(r'\\s+', ' ', text).strip()  # Replace multiple spaces with one\n",
    "#     return text\n",
    "\n",
    "# df['post_title'] = df['post_title'].apply(clean_text)\n",
    "# df['post_text'] = df['post_text'].apply(clean_text)\n",
    "# df['comment_text'] = df['comment_text'].apply(clean_text)\n",
    "\n",
    "\n",
    "# # 7. Save the preprocessed data to a new file\n",
    "# output_file_cleaned = \"reddit_posts_and_comments_cleaned.csv\"\n",
    "# df.to_csv(output_file_cleaned, index=False, encoding=\"utf-8\")\n",
    "# print(f\"Cleaned data saved to {output_file_cleaned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced data saved to reddit_posts_and_comments_enhanced.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(\"reddit_posts_and_comments.csv\")\n",
    "\n",
    "# 1. Drop rows with missing content (e.g., deleted posts/comments)\n",
    "df = df.dropna(subset=['post_title', 'post_text', 'comment_text'], how='all').reset_index(drop=True)\n",
    "\n",
    "# 2. Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# 3. Clean text: Remove non-ASCII characters, URLs, punctuation, and normalize text\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    text = text.lower()  # Normalize to lowercase\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove non-ASCII characters\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)  # Remove URLs\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Replace multiple spaces with one\n",
    "    return text\n",
    "\n",
    "df['post_title'] = df['post_title'].apply(clean_text)\n",
    "df['post_text'] = df['post_text'].apply(clean_text)\n",
    "df['comment_text'] = df['comment_text'].apply(clean_text)\n",
    "\n",
    "# 5. Extract themes\n",
    "theme_words = {\n",
    "    'charging_stations': ['station', 'stations', 'location', 'public station', 'charging point', 'infrastructure', 'charger', 'kiosk', 'EV station', 'public chargers', 'station network', 'station availability'],\n",
    "    'charging_network': ['network', 'connected', 'networked', 'charging grid', 'network coverage', 'roaming', 'charging locations', 'map', 'network reliability', 'network expansion', 'partner network'],\n",
    "    'range_anxiety': ['range', 'range anxiety', 'range fear', 'battery life', 'battery capacity', 'distance', 'travel range', 'anxiety', 'worry', 'trip range', 'unable to charge', 'running out of charge', 'mileage'],\n",
    "    'charging_speed': ['fast', 'slow', 'speed', 'charging rate', 'fast-charging', 'quick', 'fast charging', 'charging speed', 'time to charge', 'slow charging', 'quick charge', 'fast charger', 'fast charging stations'],\n",
    "    'availability_of_chargers': ['available', 'availability', 'location', 'access', 'scarce', 'scarce charging', 'find chargers', 'nearby', 'accessible', 'not available', 'out of service', 'open station', 'charger access', 'charger shortage'],\n",
    "    'cost_of_charging': ['cost', 'price', 'expensive', 'affordable', 'cheap', 'price per kWh', 'electricity cost', 'charging fees', 'rates', 'price of charging', 'cost to charge', 'free charging', 'charging cost', 'pricing model', 'pricing scheme', 'cost per session'],\n",
    "    'maintenance_issues': ['maintenance', 'repair', 'broken', 'malfunction', 'service', 'failure', 'out of service', 'maintenance required', 'charger broken', 'charger error', 'service required', 'maintenance costs', 'down time', 'maintenance issues'],\n",
    "    'tesla_charging_network': ['Tesla', 'supercharger', 'Tesla chargers', 'Tesla network', 'Tesla charging', 'supercharger station', 'Tesla charging stations', 'Tesla infrastructure', 'Tesla owners', 'Tesla charging speed'],\n",
    "    'ev_range': ['EV', 'range', 'battery', 'miles', 'distance', 'range per charge', 'battery life', 'vehicle range', 'driving range', 'range capacity', 'charge range', 'range efficiency'],\n",
    "    'vehicle model': ['tesla model 3', 'hyundai kona', 'nissan leaf', 'chevy bolt', 'bmw i3'],\n",
    "    'charging_station_location': ['houston', 'san francisco', 'los angeles', 'chicago', 'new york'],\n",
    "    'charger_type': ['charger', 'type', 'level 1', 'level 2', 'DC fast charging', 'DC fast charger', 'supercharger', 'home charger', 'wall box', 'charging adapter', 'charging port', 'connector', 'plug type', 'Type 1', 'Type 2', 'CCS', 'CHAdeMO', 'L2', 'L1'],\n",
    "}\n",
    "\n",
    "def extract_themes(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    return [word for word in theme_words if word in text]\n",
    "\n",
    "df['themes_post'] = df['post_text'].apply(extract_themes)\n",
    "df['themes_comment'] = df['comment_text'].apply(extract_themes)\n",
    "\n",
    "# 6. Sentiment analysis\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores['compound']\n",
    "\n",
    "df['sentiment_post'] = df['post_text'].apply(sentiment_analysis)\n",
    "df['sentiment_comment'] = df['comment_text'].apply(sentiment_analysis)\n",
    "\n",
    "# 7. Save the enhanced data to a new CSV file\n",
    "output_file_enhanced = \"reddit_posts_and_comments_enhanced.csv\"\n",
    "df.to_csv(output_file_enhanced, index=False, encoding=\"utf-8\")\n",
    "print(f\"Enhanced data saved to {output_file_enhanced}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
