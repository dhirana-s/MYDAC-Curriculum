{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Desktop\\coding\\MYDAC-Curriculum\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "import requests, json\n",
    "import re, string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from time import sleep\n",
    "\n",
    "# Reddit API\n",
    "import praw\n",
    "\n",
    "# Natural Language Processing (NLP)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline\n",
    "from praw import Reddit\n",
    "import concurrent.futures\n",
    "\n",
    "# Topic Modeling\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "# Visualization\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "# Transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "# Miscellaneous\n",
    "from pprint import pprint\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments Data:\n",
      "  comment_id     comment_author  comment_score  \\\n",
      "0    l3wwg7h        XxFezzgigxX             14   \n",
      "1    l3wufnj       mickthomas68             36   \n",
      "2    l3wochb        Betanumerus             30   \n",
      "3    l3wqcrs        bhilliardga              6   \n",
      "4    l3wuwj1  NotAcutallyaPanda              8   \n",
      "\n",
      "                                        comment_text  \n",
      "0  no worries as soon as batteries become more ef...  \n",
      "1  i was skeptical at first but as i already had ...  \n",
      "2  people who can charge at home have no excuse r...  \n",
      "3  ive had my ford lightning for 2 months and for...  \n",
      "4  for folks who live in or travel to rural areas...  \n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=open('cred/client_id.txt').read().strip(),\n",
    "    client_secret=open('cred/client_secret.txt').read().strip(),\n",
    "    user_agent=open('cred/user_agent.txt').read().strip(),\n",
    ")\n",
    "\n",
    "posts_to_scrape = [\n",
    "    \"https://www.reddit.com/r/electriccars/comments/1cr9w0q/32_of_consumers_were_considering_an_ev_but_cited/\",\n",
    "    \"https://www.reddit.com/r/electricvehicles/comments/1e7x13p/it_is_not_the_evs_that_are_lacking_in_the_us_its\",\n",
    "    \"https://www.reddit.com/r/science/comments/4xym1e/range_anxiety_is_scaring_people_away_from/\",\n",
    "    \"https://www.reddit.com/r/cars/comments/10wfm08/this_is_ruining_electric_cars_the_charging/\"\n",
    "]\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())    # Remove punctuation and lowercase the text\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')  # Replace newline and carriage return\n",
    "    return text\n",
    "\n",
    "data = []\n",
    "\n",
    "# Loop through each post URL\n",
    "for post_url in posts_to_scrape:\n",
    "    try:\n",
    "        submission = reddit.submission(url=post_url)\n",
    "        submission.comments.replace_more(limit=None)     # Fetch comments and remove \"More comments\"\n",
    "\n",
    "        # Check if the post has comments\n",
    "        if not submission.comments.list():\n",
    "            print(f\"No comments found for post: {post_url}\")\n",
    "            continue\n",
    "\n",
    "        # Process comments using list comprehension\n",
    "        post_data = [\n",
    "            {\n",
    "                'comment_id': comment.id,\n",
    "                'comment_author': comment.author.name if comment.author else \"Deleted\",\n",
    "                'comment_score': comment.score,\n",
    "                'comment_text': preprocess_text(comment.body)\n",
    "            }\n",
    "            for comment in submission.comments.list()\n",
    "        ]\n",
    "        \n",
    "        # Append the processed comments to the data list\n",
    "        data.extend(post_data)\n",
    "        sleep(2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing post {post_url}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Save data in chunks to CSV to prevent memory issues\n",
    "chunksize = 10000  # Larger chunks to reduce file writes\n",
    "for i in range(0, len(data), chunksize):\n",
    "    df_chunk = pd.DataFrame(data[i:i + chunksize])\n",
    "    df_chunk.to_csv(\"reddit_comments.csv\", index=False, mode='a', header=(i == 0), quotechar='\"', escapechar='\\\\', encoding='utf-8')\n",
    "\n",
    "\n",
    "\n",
    "print(\"Comments Data:\")\n",
    "print(pd.DataFrame(data).head()) \n",
    "\n",
    "pd.DataFrame(data).to_csv(\"reddit_comments.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All data collected and cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorized Data:\n",
      "  comment_id     comment_author  comment_score  \\\n",
      "0    l3wwg7h        XxFezzgigxX             14   \n",
      "1    l3wufnj       mickthomas68             36   \n",
      "2    l3wochb        Betanumerus             30   \n",
      "3    l3wqcrs        bhilliardga              6   \n",
      "4    l3wuwj1  NotAcutallyaPanda              8   \n",
      "\n",
      "                                        comment_text  \\\n",
      "0  no worries as soon as batteries become more ef...   \n",
      "1  i was skeptical at first but as i already had ...   \n",
      "2  people who can charge at home have no excuse r...   \n",
      "3  ive had my ford lightning for 2 months and for...   \n",
      "4  for folks who live in or travel to rural areas...   \n",
      "\n",
      "                                      comment_themes  \n",
      "0  [vehicle model, charger_type, charging_speed, ...  \n",
      "1  [vehicle model, charger_type, ev_range, availa...  \n",
      "2  [availability_of_chargers, charger_type, charg...  \n",
      "3  [vehicle model, charger_type, charging_speed, ...  \n",
      "4  [availability_of_chargers, ev_range, vehicle m...  \n"
     ]
    }
   ],
   "source": [
    "theme_words = {\n",
    "    'charging_stations': ['station', 'stations', 'location', 'public station', 'charging point', 'infrastructure', 'charger', 'kiosk', 'EV station', 'public chargers', 'station network', 'station availability'],\n",
    "    'charging_network': ['network', 'connected', 'networked', 'charging grid', 'network coverage', 'roaming', 'charging locations', 'map', 'network reliability', 'network expansion', 'partner network'],\n",
    "    'range_anxiety': ['range', 'range anxiety', 'range fear', 'battery life', 'battery capacity', 'distance', 'travel range', 'anxiety', 'worry', 'trip range', 'unable to charge', 'running out of charge', 'mileage'],\n",
    "    'charging_speed': ['fast', 'slow', 'speed', 'charging rate', 'fast-charging', 'quick', 'fast charging', 'charging speed', 'time to charge', 'slow charging', 'quick charge', 'fast charger', 'fast charging stations'],\n",
    "    'availability_of_chargers': ['available', 'availability', 'location', 'access', 'scarce', 'scarce charging', 'find chargers', 'nearby', 'accessible', 'not available', 'out of service', 'open station', 'charger access', 'charger shortage'],\n",
    "    'cost_of_charging': ['cost', 'price', 'expensive', 'affordable', 'cheap', 'price per kWh', 'electricity cost', 'charging fees', 'rates', 'price of charging', 'cost to charge', 'free charging', 'charging cost', 'pricing model', 'pricing scheme', 'cost per session'],\n",
    "    'maintenance_issues': ['maintenance', 'repair', 'broken', 'malfunction', 'service', 'failure', 'out of service', 'maintenance required', 'charger broken', 'charger error', 'service required', 'maintenance costs', 'down time', 'maintenance issues'],\n",
    "    'tesla_charging_network': ['Tesla', 'supercharger', 'Tesla chargers', 'Tesla network', 'Tesla charging', 'supercharger station', 'Tesla charging stations', 'Tesla infrastructure', 'Tesla owners', 'Tesla charging speed'],\n",
    "    'ev_range': ['EV', 'range', 'battery', 'miles', 'distance', 'range per charge', 'battery life', 'vehicle range', 'driving range', 'range capacity', 'charge range', 'range efficiency'],\n",
    "    'vehicle model': ['tesla model 3', 'hyundai kona', 'nissan leaf', 'chevy bolt', 'bmw i3'],\n",
    "    'charging_station_location': ['houston', 'san francisco', 'los angeles', 'chicago', 'new york'],\n",
    "    'charger_type': ['charger', 'type', 'level 1', 'level 2', 'DC fast charging', 'DC fast charger', 'supercharger', 'home charger', 'wall box', 'charging adapter', 'charging port', 'connector', 'plug type', 'Type 1', 'Type 2', 'CCS', 'CHAdeMO', 'L2', 'L1'],\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)  # Convert 'data' to DataFrame if it's not already\n",
    "\n",
    "# Initialize BERT-based zero-shot classifier\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Function to categorize text (both post and comment)\n",
    "def categorize_text_bert(text, candidate_labels):\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return []  # Return empty list if text is missing or empty\n",
    "    result = classifier(text, candidate_labels)\n",
    "    return result['labels']\n",
    "\n",
    "# Function to categorize posts and comments\n",
    "def categorize_comments(df, theme_words):\n",
    "    categorized_data = []\n",
    "\n",
    "    # Loop through the comments\n",
    "    for index, row in df.iterrows():\n",
    "        # Categorize comment text\n",
    "        comment_themes = categorize_text_bert(row['comment_text'], list(theme_words.keys()))\n",
    "\n",
    "        categorized_data.append({\n",
    "            'comment_id': row['comment_id'],\n",
    "            'comment_author': row['comment_author'],\n",
    "            'comment_score': row['comment_score'],\n",
    "            'comment_text': row['comment_text'],\n",
    "            'comment_themes': comment_themes\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(categorized_data)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Categorize the comments\n",
    "categorized_df = categorize_comments(df, theme_words)\n",
    "\n",
    "# Display the categorized data (Comments)\n",
    "print(\"Categorized Data:\")\n",
    "print(categorized_df.head())\n",
    "\n",
    "categorized_df.to_csv(\"categorized_comments_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
